# Spark
Windows 本地配置spark开发环境
1. 安装JDK <br>
   JDK下载路径 ： https://www.oracle.com/cn/java/technologies/downloads/ <br>
   安装好后配置环境变量：<br>
    新建JAVA_HOME <br>
    ![image](https://user-images.githubusercontent.com/28624027/210785889-6bb5eb1e-72dd-4041-bf53-ca53946f000e.png) <br>
    在Path中添加JAVA_HOME/bin <br>
    ![image](https://user-images.githubusercontent.com/28624027/210792989-03ec94dd-8619-4897-b1d4-68a593c58555.png) <br>
   设置完成后在CMD命令窗口输入java -version验证是否安装成功 <br>
   ![image](https://user-images.githubusercontent.com/28624027/210793293-646633ce-3a81-48f2-b266-e0d9457166e2.png) <br>


2. 安装Spark
   
4. 安装Scala
5. 安装Hadoop
